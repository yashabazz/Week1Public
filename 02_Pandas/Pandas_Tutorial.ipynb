{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "Pandas_Tutorial",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-UimMCmGe19F"
      },
      "source": [
        "# Pandas Tutorial \n",
        "Pandas is a python library commonly used for analyzing, filtering and manipulating data. It works particularly well with any tabular (\"table like\") data, including the data sets that we will be using during Week 1. In this notebook, we will explore how pandas can be used to read, visualize, and modify data sets. For further information, see the pandas documentation website here: https://pandas.pydata.org/docs/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9h0O_mJm4tqq"
      },
      "source": [
        "## Pima Diabetes Dataset\n",
        "\n",
        "This notebook tutorial and most of the other tutorial notebooks for this week will use data from the Pima Diabetes Dataset. The set we will use can be accessed with the following direct link:\n",
        "\n",
        "https://raw.githubusercontent.com/BeaverWorksMedlytics2020/Data_Public/master/NotebookExampleData/Week1/diabetes.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zEySp-HkgFps"
      },
      "source": [
        "### About the data:\n",
        "\n",
        "All patients here are females at least 21 years old of Pima Native American heritage.\n",
        "\n",
        "- **Pregnancies**: Number of times pregnant\n",
        "- **Glucose**: Plasma glucose concentration 2 hours in an oral glucose tolerance test\n",
        "- **BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "- **SkinThickness**: Triceps skin fold thickness (mm)\n",
        "- **Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "- **BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "- **DiabetesPedigreeFunction**: A function that scores the likelihood of diabetes based on family history.\n",
        "- **Age**: Age (years)\n",
        "- **Outcome**: 1 (has diabetes) or 0 (no diabetes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xPvBcxz7hiAG"
      },
      "source": [
        "## Reading CSV files with pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2IfN2ZFgs9wh"
      },
      "source": [
        "Pandas can read data directly from a url. There are a number of options associated with the **read_csv** function, but for now we will just pass a list of the column labels, since our CSV does not contain them. Without this option, the first row of data would be interpreted as labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5NLRPp9BdzOX",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/BeaverWorksMedlytics2020/Data_Public/master/NotebookExampleData/Week1/diabetes.csv\"\n",
        "\n",
        "\"\"\"\n",
        "      'preg': number of pregnancies  \n",
        "      'plas': plasma glucose concentration \n",
        "      'pres': blood pressure \n",
        "      'skin': skin thickness\n",
        "      'test': Insluin\n",
        "      'mass': BMI\n",
        "      'pedi': diabetes pedigree function\n",
        "      'age': age\n",
        "      'class': '0' means does not have diabetes and '1' means has diabetes\n",
        "\"\"\"\n",
        "\n",
        "# Define explicit list of column headers to pass to pandas\n",
        "our_names = ['preg','plas','pres','skin','test','mass','pedi','age','class']\n",
        "data = pd.read_csv(url, names=our_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9W7LvINwuJtV"
      },
      "source": [
        "Now that we've imported the data, let's take a closer look at the python object that was created by pandas. First, what is the object's type?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZ1FW3lhiPtD",
        "colab": {}
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vrk0TLFRujUe"
      },
      "source": [
        "DataFrame is a very general structure for 2-dimensional tabular data. It contains column labels, is size-mutable, and may contain heterogeneous data (this means data may be missing, or of mixed types). There are a number of ways to get information about a DataFrame. Each of the following code segments will demonstrate one such way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SopMMUT1f-nV",
        "colab": {}
      },
      "source": [
        "# Show the first 10 entries in the DataFrame (from the \"head\")\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u0GiNip3hnFs",
        "colab": {}
      },
      "source": [
        "# Get the dimensionality of the DataFrame (number of rows, columns)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SSz4bg6UrZPG",
        "colab": {}
      },
      "source": [
        "# Find the number of entries for each column\n",
        "data.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "85mCDaaUipPu",
        "colab": {}
      },
      "source": [
        "# Create a string that describes the shape of the dataset\n",
        "\"There are \" + str(data.shape[0]) + \" people in the study with \" + str(data.shape[1]) + \" variables each \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pYqzEDuS04SK",
        "colab": {}
      },
      "source": [
        "# Generate a table of statistical information describing the dataset\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p5lZ5dsRwHKK"
      },
      "source": [
        "Try using tab complete to see other functions and variables associated with DataFrames, or explore the API documentation:\n",
        "\n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vOAdRSTAlu1A"
      },
      "source": [
        "## Slicing and Dicing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p4GjOKyhxIUL"
      },
      "source": [
        "Slicing and dicing are technical terms for subselecting parts of a multi-dimensional dataset. To **slice** a dataset is to choose a value for one dimension, and take all data that matches. This results in a subset that is one dimension smaller. For example, in our dataset we could slice a single row or column. To **dice** data is to choose ranges in multiple dimensions, creating a more arbitrary subset.\n",
        "\n",
        "To take a simple example, selecting a value from a python list by index is technically a slice (1-D to 0-D). Selecting a range of indices would be a dice. Pandas allows for similar data access, either by index or label. Here are some examples:\n",
        "<br></br>\n",
        "\n",
        "**iloc**: Indexing with integers. Accepts single values [ i ], lists [ i, j ], or ranges [ i : j : k ]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_3FVIi860jLt",
        "colab": {}
      },
      "source": [
        "# Single-row slice\n",
        "data.iloc[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9C2s__Ni1Eq",
        "colab": {}
      },
      "source": [
        "# Dicing the first three rows\n",
        "data.iloc[0:3]  # NOTE: equivalent to data.iloc[0:3:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ds3HLB3JnPea",
        "colab": {}
      },
      "source": [
        "# 2-D dice of the first 3 rows, but only the last two columns\n",
        "data.iloc[0:3, 7:]  # NOTE: equivalent to data.iloc[0:3:1, 7:9:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oBTayeAnquFd"
      },
      "source": [
        "**loc**: Indexing with column labels, which are strings for columns and integers for rows. Accepts single values [ 'pres' ], lists [ 'pres', 'class' ], or \"label slices\" [ 'pres' : 'class' ]. Note that the \"label slice\" is not a range, so the terminal value will be included. This is particularly confusing with row labels, because the syntax for a slice will resemble an integer range, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cw5M4JHunhvm",
        "colab": {}
      },
      "source": [
        "# Dice the first three rows, with data in the columns from 'pres' to 'class'\n",
        "data.loc[0:2, 'pres':'class'] # NOTE: 0:2 is a slice, not a range, and includes index 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rHns1NFrrzDe"
      },
      "source": [
        "## Chained Indexing/Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8p0ijE3E4vfr"
      },
      "source": [
        "Now we know how to subselect data, but that's not very useful unless we know what data we want to subselect. One solution is to create a data **mask**. In this context, the mask is a list of indices corresponding to data that meets certain criteria. For example, we can create a mask for all data for people with an age greater than 39. Doing so is quite simple in pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T9ui-mfbujed",
        "colab": {}
      },
      "source": [
        "# Create a pandas series \"mask\" for rows with an age greater than 39\n",
        "data_age_boolean = data.age > 39\n",
        "# Show the created boolean series\n",
        "data_age_boolean.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N1DmFyel6ZOD"
      },
      "source": [
        "The created object is a series of True/False values for each row. Let's double check the first three values for age."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mx7DyR-zwJgU",
        "colab": {}
      },
      "source": [
        "# Show the first three age values. Only value 0 is greater than 39.\n",
        "data['age'].head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DqkgI6A9vqkr",
        "colab": {}
      },
      "source": [
        "# Show the first three values in the boolean mask. Only value 0 should be TRUE.\n",
        "data_age_boolean.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PIgN9CjQ68nt"
      },
      "source": [
        "The series object can be used to access a subset of the data. This is effectively filtering the entire dataset to return only entries with an age greater than 39."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yFP_Wq7jwZnY",
        "colab": {}
      },
      "source": [
        "# Subselect data that meets the condition set by data_age_boolean\n",
        "filtered_dataframe_by_age = data[data_age_boolean]\n",
        "# Display the resulting filtered data\n",
        "filtered_dataframe_by_age"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z2HTMPIo7jDR"
      },
      "source": [
        "Notice that while the filtered output is only 207 rows, the row label goes up to 766. This is because the subselected rows have kept their original labels. Row \"766\" is the 207th row in our new structure. This can be important if we want to refer back to the original dataset.\n",
        "\n",
        "Often we will want to apply more than one filter to our data. Fortunately, since the masks are just booleans, it is intuitive and easy to combine masks. For example, if we want to combine our age filter with a second filter, we can use a logical \"and\" operator (&) like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "othXawuotKDD",
        "colab": {}
      },
      "source": [
        "# Subselect data with age greater than 39 and more than 2 pregnancies\n",
        "filtered_dataframe_age_preg = data[data_age_boolean & (data['preg'] > 2)]\n",
        "# Display the filtered data\n",
        "filtered_dataframe_age_preg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ll3S3Ayc9K3e"
      },
      "source": [
        "Now we've reduced our subset to just 172 entries. Also, while the original row labels are still maintained, row \"766\" has been filtered out!\n",
        "\n",
        "As a final note, you can also combine filters with the \"or\" operator (|). We would expect this to produce a subset of equal or larger size than either filter on its own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jau0Y-qA9wrV",
        "colab": {}
      },
      "source": [
        "# Subselect data with age greater than 39 OR more than 2 pregnancies\n",
        "filtered_dataframe_age_preg = data[data_age_boolean | (data['preg'] > 2)]\n",
        "# Display the filtered data\n",
        "filtered_dataframe_age_preg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WfUukmFVGKz",
        "colab_type": "text"
      },
      "source": [
        "You can also sort the values in a dataframe by ascending or descending order. This can be useful for quickly viewing, for example, all of the subjects who have had more than 12 pregnancies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uauHzxnyVGK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = filtered_dataframe_age_preg.sort_values(by='preg', ascending=False, na_position='first') #descending order\n",
        "sample #ordered based on \"preg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2PHGRBRVGLB",
        "colab_type": "text"
      },
      "source": [
        "# Dealing with missing data\n",
        "\n",
        "Not all datasets are created whole. Survey respondents may accidentally skip a question, some lab equipement could malfunction, or the handwriting for an answer may be illegible to the people entering the data into a computer. Anyway it could happen, and missing data is annoying!\n",
        "\n",
        "There are a few ways to go about fixing those fields in your data, each with their own advantages and disadvantages. We'll continue using the Pima diabetes dataset to demonstrate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mtjl0mEVGLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9z0lp0rVGLG",
        "colab_type": "text"
      },
      "source": [
        "Now if you look into the dataframe you'll see some odd, or rather **missing**, values. We can tell that these are missing values from knowing what the columns stand for; for example it wouldn't make sense for someone to have a blood pressure or BMI of 0 right? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwZYVlQ9VGLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Looking at the columns with 0s\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfCGh0HYVGLJ",
        "colab_type": "text"
      },
      "source": [
        "You can see from the 4th row showing minimum values that 'preg', 'plas', 'pres', 'skin', 'test', 'mass', and 'class' have 0s. On the other hand don't forget that for columns like number of pregnancies and class, a 0 is perfectly valid.\n",
        "\n",
        "_This is why it's important that you know what type of data you're handling!_\n",
        "\n",
        "To summarize, the columns with invalid 0s (missing data) are:\n",
        "- plas\n",
        "- pres\n",
        "- skin\n",
        "- test\n",
        "- mass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZdprkcbVGLJ",
        "colab_type": "text"
      },
      "source": [
        "## Replacing with a constant\n",
        "\n",
        "A lot of times when data is missing the cell is simply left blank or filled with NaNs or constant; in our case **_they have already been replaced with the constant 0_**. However as said before we want to keep the 0s in columns representing pregnancies and class so it'd be best to somehow differentiate these missing and valid values.\n",
        "\n",
        "NaN stands for \"Not a Number\" and is usually used for missing entries in a dataframe. Let's go ahead and replace the invalid 0s with NaNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMcrdkWMVGLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "invalid = ['plas', 'pres', 'skin', 'test', 'mass']\n",
        "\n",
        "for i in invalid:\n",
        "    data[i].replace(to_replace=0, value=np.nan, inplace=True)\n",
        "\n",
        "data.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52a4Mb97VGLN",
        "colab_type": "text"
      },
      "source": [
        "**Pros**\n",
        "- easiest and quickest way to deal with missing values\n",
        "\n",
        "\n",
        "**Cons**\n",
        "- can introduce bias and skew data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2OaKwGVVGLN",
        "colab_type": "text"
      },
      "source": [
        "## Dropping rows\n",
        "\n",
        "One of the next easiest ways to deal with NaNs is simply deleting rows with missing information. Luckily, pandas already has a beautiful function just for that purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnH-d1TzVGLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_row = data.dropna(axis=0).reset_index(drop=True) # axis: 0=row, 1=column\n",
        "\n",
        "data_row.head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITWvVK0DVGLQ",
        "colab_type": "text"
      },
      "source": [
        "But be cautious with dropping rows, depending on how many rows had NaNs and the size of your data. You may inadvertently drastically decrease the sample size. As you can see below, we lost about half of our data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5liVVD3MVGLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Original size: \", data.shape)\n",
        "print(\"With rows dropped: \", data_row.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykQHDIy9VGLT",
        "colab_type": "text"
      },
      "source": [
        "**Pros**\n",
        "- again, easy and quick to apply to data\n",
        "\n",
        "**Cons**\n",
        "- reduces sample size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnNB71y-VGLT",
        "colab_type": "text"
      },
      "source": [
        "## Dropping the variable (column)\n",
        "\n",
        "If the majority of the column were filled with NaNs (ie >70% but it's up to you to determine your own rule of thumb) and thus not very important in predicting the targeted label, dropping the variable makes sense. Although overall, it would be unwise to drop a variable just because it has NaNs; as you can see in our data that would mean dropping 5 of our 9 columns!\n",
        "\n",
        "For an example's sake, let's drop the column containing the most NaNs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwEmY2QHVGLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in invalid:\n",
        "    count = data[i].isna().sum()\n",
        "    print(i, \": \", count, \"NaNs, \", ((count/(len(data.index))) * 100), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TI3FbqqVGLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_col = data.drop(['test'], axis=1)\n",
        "\n",
        "data_col.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq8lNQsWVGLZ",
        "colab_type": "text"
      },
      "source": [
        "**Pros**\n",
        "- can clean up unnecessary data and speed up processing\n",
        "\n",
        "**Cons**\n",
        "- reduces data and number of potential features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfmVYILCVGLZ",
        "colab_type": "text"
      },
      "source": [
        "## Replacing with the mean/median\n",
        "\n",
        "We can also deal with missing values by replacing them with the mean or median if the column's numerical. Like dropping NaNs, filling NaNs with a constant value can be done with a single function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFgfc5MfVGLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in invalid:\n",
        "    data[i].fillna(data[i].mean(), inplace=True) #use data[i].median() for median\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhBlTzFkVGLd",
        "colab_type": "text"
      },
      "source": [
        "**Pros**\n",
        "- easy and straightforward (calculate, find, & replace)\n",
        "\n",
        "**Cons**\n",
        "- skews data to be biased towards the center, underestimating the variance in our data "
      ]
    }
  ]
}
