{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Challenge_Project_STUDENT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn6VZ_1yQap8",
        "colab_type": "text"
      },
      "source": [
        "# Week 1 Challenge Project\n",
        "This is the complete notebook, which includes both the data cleaning and visualization section released on Day 2, and additional guidelines for model creation and evaluation. If you were already working on the notebook from before, you may have to copy your work over.\n",
        "\n",
        "At the end of this notebook, there is also a description of how to finalize and present your project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQDE8pPCpFRb",
        "colab_type": "text"
      },
      "source": [
        "## Challenge Introduction\n",
        "\n",
        "> Original author: Lyle Lalunio\n",
        "\n",
        "Hypothyroidism, also called underactive thyroid or low thyroid, is a disorder of the endocrine system in which the thyroid gland does not produce enough thyroid hormone. It can cause a number of symptoms, such as poor ability to tolerate cold, a feeling of tiredness, constipation, depression, and weight gain. Occasionally there may be swelling of the front part of the neck due to goitre. Untreated hypothyroidism during pregnancy can lead to delays in growth and intellectual development in the baby or cretinism.\n",
        "\n",
        "Worldwide, too little iodine in the diet is the most common cause of hypothyroidism. In countries with enough iodine in the diet, the most common cause of hypothyroidism is the autoimmune condition Hashimoto's thyroiditis. Less common causes include: previous treatment with radioactive iodine, injury to the hypothalamus or the anterior pituitary gland, certain medications, a lack of a functioning thyroid at birth, or previous thyroid surgery. The diagnosis of hypothyroidism, when suspected, can be confirmed with blood tests measuring thyroid-stimulating hormone (TSH) and thyroxine levels.\n",
        "\n",
        "Worldwide about one billion people are estimated to be iodine deficient; however, it is unknown how often this results in hypothyroidism. In the United States, hypothyroidism occurs in 0.3â€“0.4% of people.\n",
        "\n",
        "And that is why we iodize salt.\n",
        "\n",
        "![alt text](https://www.mayoclinic.org/-/media/kcms/gbs/patient-consumer/images/2013/11/15/17/39/ds00181_-ds00344_-ds00353_-ds00491_-ds00492_-ds00567_-ds00660_-my00709_im01872_thyroid_gif.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFF1-BLiSLZ8",
        "colab_type": "text"
      },
      "source": [
        "Background: Doctors all around the world need our help to predict whether a patient has hypothyroid disease. We have already overspent our budget to collect such complete data on about 30 attributes for 2800 patients--a good starting number, but a larger sample would certainly be preferred. Moving forward, however, we simply cannot afford to spend so much money on data collection. Therefore, we also need to determine which attributes are the most meaningful to the predictive models, and cut out the rest that don't contribute much. \n",
        "\n",
        "The boss wants to see a **balanced** model that can predict with a **high sensitivity** and **high specificity** while using a ***low amount of features***. Collecting complete data such as this is very rare, very time-consuming, and often very expensive. By minimizing the number of features, it will optimize future data collection by deciding what needs to be collected, and what doesn't."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsZB_SGvp4mP",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWrUz9OQ0uAU",
        "colab_type": "text"
      },
      "source": [
        "Let's read the data into a Pandas dataframe and look at the first 20 records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9AtXQPkzC8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as po\n",
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYhtoqdR6Y3J",
        "colab_type": "text"
      },
      "source": [
        "Great, looks like the data loaded in properly. Let's continue looking at some summary statistics on our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGKbG-eBqBjF",
        "colab_type": "text"
      },
      "source": [
        "## Viewing summary statistics\n",
        "The functions describe() and info() are your friends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnp3nN9b6ZNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QndSspU7lW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olpFokrp8AIH",
        "colab_type": "text"
      },
      "source": [
        "Note the data types are all objects--even columns that are obviously numeric like Age.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0emOppVyqQS9",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRQpnByEWrcx",
        "colab_type": "text"
      },
      "source": [
        "To start, let's make all the numerical columns contain the correct type of values and change the data type of those columns to numeric. Let's also replace all those question marks with the median of the respective column.\n",
        "\n",
        "Hint: To make it easier, first try converting all the \"?\" to NaN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlTsaK5n5Bg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "### your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZo7iKHUD3DG",
        "colab_type": "text"
      },
      "source": [
        "Hmm, still looks like the TBG column is unfilled, implying it was empty to begin with. Let's get rid of this column, then (and make sure to get rid of it in your list of numeric columns, too!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAe5FIFkD25f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTjWD_ddCHsA",
        "colab_type": "text"
      },
      "source": [
        "All right, let's take a look now at the info of *just the numeric columns* in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00OaxCAbzRvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "copy[numeric_columns].info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOzcRX-5YRvz",
        "colab_type": "text"
      },
      "source": [
        "Perfect, now let's fix that class feature. According to the note the data collectors included with this data, the \".|####\" refers to a patient number, and is not necessarily relevant for our purposes here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFmeyRcGYR7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYOwWnpqhQvd",
        "colab_type": "text"
      },
      "source": [
        "Let's run the describe() function on just the \"class\" column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq_v45R8hP5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['class'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6S7Y6VXhYct",
        "colab_type": "text"
      },
      "source": [
        "It looks like there are actually 4 unique classification variables! Thank goodness we didn't assume it was binary.\n",
        "\n",
        "Display all the unique values in the class column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH0fTzzvE-oF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBrmRJHakpWm",
        "colab_type": "text"
      },
      "source": [
        "But let's make it binary for the sake of this example anyway. If you finish early later on, try the multiclass classifier with all 4 values!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwqVoUFTkoa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbgWOvekhluw",
        "colab_type": "text"
      },
      "source": [
        "Before we move on, let's not forget to run the describe() function on just  your categorical columns, too.\n",
        "Compare it to the describe() that your numeric columns produce."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHAZCbNAc5KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo9aRzltCOK8",
        "colab_type": "text"
      },
      "source": [
        "Great! Let's see if there's any other records we have to address. count() is a nice way to check if we have any other missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1yGe8nrzozW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y9DDq8qCeL8",
        "colab_type": "text"
      },
      "source": [
        "We could replace the missing values in proportion to the current number of males and females over the total, but that is making an assumption we don't have to make. For now, let's simply cut the records of all these sexless people out of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E6qS7F5zyt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTcS25EHF4vL",
        "colab_type": "text"
      },
      "source": [
        "Nice! Now we have a pretty clean dataset to work with. Let's now do some further data analysis and visualization to better understand what we're working with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsiaTCjQql3S",
        "colab_type": "text"
      },
      "source": [
        "## Data analysis and visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huFOG2Mw3OqJ",
        "colab_type": "text"
      },
      "source": [
        "Check the correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXrXSMW_GSeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfm6AEv3YIJ",
        "colab_type": "text"
      },
      "source": [
        "Convert the class feature to numeric so we can also see the correlations it has with the numeric features, and check the correlation again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bGleemH3o3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as po\n",
        "### Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp4yO5kUGd3L",
        "colab_type": "text"
      },
      "source": [
        "Let's do some further visual analysis using a new module called seaborn. Explore its incredible versatility and diversity with data visualization here: https://seaborn.pydata.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzkaBa64aXzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(copy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvW7_0aWFSEm",
        "colab_type": "text"
      },
      "source": [
        "OK! I think we're ready to create and select some supervised learning models. To get the ball rolling, select Age and Sex as our explanatory features (and class as the target feature, obviously)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXMQ9UaKqyha",
        "colab_type": "text"
      },
      "source": [
        "## Model training and selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mon3ih88tW8y",
        "colab_type": "text"
      },
      "source": [
        "Let's use get_dummies on the categorical variables (but not the class value!) to view the column names to select some for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NqvPYi6itkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yEeqjv19hCX",
        "colab_type": "text"
      },
      "source": [
        "All right, let's now split our data into training and testing in an 80-20 split. For consistency, let's all use a seed of 8675309."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQqlCTGntXCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KGUCXBE-OFy",
        "colab_type": "text"
      },
      "source": [
        "For reusability, let's make a logistic regression function that will take our training and testing data as arguments. Inside the function, build a model on your training data, fit it with your training class data, and return a list of your predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DawvoHd7lnG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def log_reg(train_X,train_Y,test_X,test_Y):\n",
        "\n",
        "  ### Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR8xu_VVsygN",
        "colab_type": "text"
      },
      "source": [
        "Fantastic, we have just built a logistic regression model! Let's go see how well it performs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAz096POwSRJ",
        "colab_type": "text"
      },
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "570duVNhrTZh",
        "colab_type": "text"
      },
      "source": [
        "To start, let's establish the baseline performance. This is important because it provides a starting point of comparison for later evaluation methods, like accuracy.\n",
        "\n",
        "A good baseline model to use is the Zero Rule algorithm. In classification problems, it simply predicts the class value with the greatest number of instances every time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwvqucK_Yg-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zero_rule_algorithm_classification(train,test):\n",
        "  ## Your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_nExUgUYll5",
        "colab_type": "text"
      },
      "source": [
        "Get your baseline performance by calculating the accuracy of your Zero Rule algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs0M8OdtYidB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WksirqfT5Ecw",
        "colab_type": "text"
      },
      "source": [
        "So maybe accuracy isn't the best performance measure for this dataset. As you've seen already, even when the models predict \"negative\" for all the records, we could already achieve a ~92% accuracy. However, that also implies we incorrectly predicted 100% of the positive cases, which in the context of this problem, is fatal.\n",
        "\n",
        "Thankfully, it isn't the only way to evaluate your model. Let's start by creating a confusion matrix using the logistic regression function you built earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSS7JdYjaBWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0JPOHmQn8N6",
        "colab_type": "text"
      },
      "source": [
        "Hopefully you remember our discussion of the Area Under the Receiver Operator Curve metric. This can measure the accuracy of a test to discriminate diseased cases from normal cases.\n",
        "\n",
        "When you consider the results of a particular test in two populations, one population with a disease, the other population without the disease, you will rarely observe a perfect separation between the two groups. Hence, the overlapping areas in the diagram below (FN, FP).\n",
        "\n",
        "To review, on a Receiver Operating Characteristic (ROC) curve, the true positive rate is plotted in function of the false positive rate for different cut-off points. Each point on the ROC curve represents a sensitivity/specificity pair corresponding to a particular decision threshold. A test with perfect discrimination (no overlap in the two distributions) has a ROC curve that passes through the upper left corner. Therefore the closer the ROC curve is to the upper left corner, the higher the overall accuracy of the test.\n",
        "\n",
        "![alt text](https://www.medcalc.org/manual/_help/images/roc_intro1.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvTWQTcycBEp",
        "colab_type": "text"
      },
      "source": [
        "Now, to graph the AUROC curve, we will need to predict probabilities of choosing a specific class value rather than the class value itself. Make a new logistic regression model that does so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur0s4m3kg3H-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm0yv6wmDnQz",
        "colab_type": "text"
      },
      "source": [
        "Now calculate the area under the receiver operator curve with your predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xRxhlqbcc-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3hnQOGUczOn",
        "colab_type": "text"
      },
      "source": [
        "Now graph the ROC curve using matplotlib, fully labeled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA-ieOGua55H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "### Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D4BtDZV6fxV",
        "colab_type": "text"
      },
      "source": [
        "In conclusion, it looks like this model performed pretty bad. It's probably best to try out different columns or perhaps use a different model before we submit our model for scoring. Get creative!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSdZEiLMTXdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JW3myd8LHJy",
        "colab_type": "text"
      },
      "source": [
        "## Submitting your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuexs1daLNBY",
        "colab_type": "text"
      },
      "source": [
        "Once you believe to have found the best classifier, run your classifier on the test data and make a pickle file containing of your predictions contained a pandas dataframe.\n",
        "\n",
        "This pandas dataframe will contain three columns for your binary classifier (or 5 columns for the multiclass classifier): the first column should be your model's \"best guess\" for each patient (either 0 or 1, negative or positive) and the last two columns should be the probability the patient would be classified as either a 0 or 1.\n",
        "\n",
        "(see below for reference)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkZOEgg3m3g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pickling example\n",
        "import pickle\n",
        "predictions=po.DataFrame({\"guesses\":[0,1,0,1],\"prob_neg\":[.75,.15,.63,.20],\"prob_pos\":[.25,.85,.27,.80]})\n",
        "prediction_pickle_path = 'prediction_pickle.pkl'\n",
        "\n",
        "from google.colab import files\n",
        "# Create an variable to pickle and open it in write mode\n",
        "prediction_pickle = open(prediction_pickle_path, 'wb')\n",
        "pickle.dump(predictions, prediction_pickle)\n",
        "files.download(prediction_pickle_path)\n",
        "prediction_pickle.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj6_AB6LnjrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_unpickle = open(prediction_pickle_path, 'rb')\n",
        " \n",
        "# load the unpickle object into a variable\n",
        "predictions = pickle.load(prediction_unpickle)\n",
        " \n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgFVRWQzXFWl",
        "colab_type": "text"
      },
      "source": [
        "We will compare your guesses with the true classifications to score your model using the AUC metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW27RtFNttQA",
        "colab_type": "text"
      },
      "source": [
        "## Presenting your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8A1npNnUYey",
        "colab_type": "text"
      },
      "source": [
        "Finally, we would like you to be able to present your model to the class. Prepare a notebook with the following things:\n",
        "\n",
        "* **Features Chosen:** a list of the features used in your model, and an explanation of how you chose them.\n",
        "* **Type of Model:** an explanation of the model type, parameters used, and why.\n",
        "* **Evaluation:** at least one plot showing an evaluation of your model against a validation set. You can use a confusion matrix, AUROC, or another metric of your choice.\n",
        "\n",
        "Feel free to include one or two additional plots that describe your process and/or model if you think that would be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w66lpbB6Qv_M",
        "colab_type": "text"
      },
      "source": [
        "## Moving to the Next Level"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-HZ12lht_so",
        "colab_type": "text"
      },
      "source": [
        "For those that finish early, remember how we converted the class values into the binary of \"negative\" and \"positive\"? Now try tackling the multiclass classifier (predicting the different types of positive hypothyroid cases instead of simply negative or positive)! \n",
        "\n",
        "The same rules apply!"
      ]
    }
  ]
}